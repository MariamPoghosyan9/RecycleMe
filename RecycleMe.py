# -*- coding: utf-8 -*-
"""Sas

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1vLaokaB8rkDe39Zhauh0_KzV9ID5D5EO
"""

import requests
import pandas as pd

for page_number in range(0,2):
  url = "https://www.sas.am" + str(page_number + 1)
  response = requests.get(url)
  print(response)

from bs4 import BeautifulSoup
import requests

product_list = []

# Define the URL of the page to scrape
url = "https://www.sas.am/catalog/molochnye_produkty/"
response = requests.get(url)

if response.status_code == 200:  # Check if request was successful
    soup = BeautifulSoup(response.content, "html.parser")
    print("Page content fetched successfully.")

    # Locate the product slider
    product_slider = soup.find("div", class_="product-slider__slider")
    if product_slider:
        print("Product slider found.")

        # Locate each product within the slider
        each_product = product_slider.find_all("div", class_="product-slider__slide")
        print(f"Found {len(each_product)} products.")

        for item in each_product:
            # Extract product details
            product_name = item.find("div", class_="product__name")
            product_price = item.find("div", class_="price__new")
            product_code = item.find("input", {"name": "id"})  # Hidden input field
            product_availability = item.find("div", class_="counter__tooltip-text")

            # Store the data
            product_data = {
                'Ապրանքի անվանում': product_name.text.strip() if product_name else 'N/A',
                'Գին': product_price.find("span", class_="price__text").text.strip() if product_price else 'N/A',
                'Ապրանքի կոդ': product_code["value"] if product_code else 'N/A',
                'Հասանելիություն': product_availability.text.strip() if product_availability else 'N/A',
            }
            product_list.append(product_data)
    else:
            print("Product slider not found.")
else:
    print(f"Failed to fetch the page. Status code: {response.status_code}")

# Print the scraped data
print("\nScraped Products:")
for product in product_list:
    print(product)

df = pd.DataFrame(product_list)
print(df)

df.info()

df.isnull()

from bs4 import BeautifulSoup
import requests

product_list = []

# Define the URL of the page to scrape
url = "https://www.sas.am/catalog/molochnye_produkty/"
response = requests.get(url)

if response.status_code == 200:  # Check if request was successful
    soup = BeautifulSoup(response.content, "html.parser")
    print("Page content fetched successfully.")

    # Locate the product slider
    product_slider = soup.find("div", class_="product-slider__slider")
    if product_slider:
        print("Product slider found.")

        # Locate each product within the slider
        each_product = product_slider.find_all("div", class_="product-slider__slide")
        print(f"Found {len(each_product)} products.")

        for item in each_product:
            # Extract product details
            product_name = item.find("div", class_="product__name")
            product_price = item.find("div", class_="price__new")
            product_code = item.find("input", {"name": "id"})  # Hidden input field
            product_availability = item.find("div", class_="counter__tooltip-text")

            # Store the data
            product_data = {
                'Ապրանքի անվանում': product_name.text.strip() if product_name else 'N/A',
                'Գին': product_price.find("span", class_="price__text").text.strip() if product_price else 'N/A',
                'Ապրանքի կոդ': product_code["value"] if product_code else 'N/A',
                'Հասանելիություն': product_availability.text.strip() if product_availability else 'N/A',
            }
            product_list.append(product_data)
    else:
        print("Product slider not found.")
else:
    print(f"Failed to fetch the page. Status code: {response.status_code}")

# Print the scraped data
print("\nScraped Products:")
for product in product_list:
    print(product)

import pandas as pd
from bs4 import BeautifulSoup
import requests

product_list = []
# կարագ, մարգարին
# Define the URL of the page to scrape
url = "https://www.sas.am/catalog/slivochnoe/?LIMIT=48"
response = requests.get(url)

if response.status_code == 200:  # Check if request was successful
    soup = BeautifulSoup(response.content, "html.parser")
    print("Page content fetched successfully.")

    # Locate the product grid
    product_grid = soup.find("div", class_="catalog__grid grid")
    if product_grid:
        print("Catalog grid found.")

        # Locate each product within the grid
        each_product = product_grid.find_all("div", class_="catalog__col col-xl-3 col-lg-3 col-md-4 col-sm-6 col-xs-12")
        print(f"Found {len(each_product)} products.")

        for item in each_product:
            # Extract product details
            product_name = item.find("div", class_="product__name hidden visible-sm")  # Updated class for name
            product_price = item.find("div", class_="product__price-wrap flc")  # Updated class for price
            product_code = item.find("input", {"name": "id"})  # Hidden input field for product code
            product_availability = item.find("div", class_="product__availability")  # Adjust based on actual class

            # Clean and process the price
            price = product_price.text.strip() if product_price else 'N/A'
            price = price.replace(" դր", "").replace(",", "").strip()  # Remove currency and clean format
            price = int(price) if price.isdigit() else price  # Convert to integer if it's numeric

            # Store the data
            product_data = {
                'Ապրանքի անվանում': product_name.text.strip() if product_name else 'N/A',
                'Գին': price,
                'Ապրանքի կոդ': product_code["value"] if product_code else 'N/A',
                'Հասանելիություն': 'Available' if product_price else 'Unavailable',  # Example for availability
            }
            product_list.append(product_data)
    else:
        print("Product grid not found.")
else:
    print(f"Failed to fetch the page. Status code: {response.status_code}")

# Create a DataFrame from the scraped data
df = pd.DataFrame(product_list)

# Display the DataFrame
print("\nScraped Products:")
print(df)

# Optionally, save to a CSV file
df.to_csv("scraped_products.csv", index=False, encoding='utf-8')

import pandas as pd
from bs4 import BeautifulSoup
import requests

product_list = []
# կաթ
# Define the URL of the page to scrape
url = "https://www.sas.am/catalog/moloko/?LIMIT=60"
response = requests.get(url)

if response.status_code == 200:  # Check if request was successful
    soup = BeautifulSoup(response.content, "html.parser")
    print("Page content fetched successfully.")

    # Locate the product grid
    product_grid = soup.find("div", class_="catalog__grid grid")
    if product_grid:
        print("Catalog grid found.")

        # Locate each product within the grid
        each_product = product_grid.find_all("div", class_="catalog__col col-xl-3 col-lg-3 col-md-4 col-sm-6 col-xs-12")
        print(f"Found {len(each_product)} products.")

        for item in each_product:
            # Extract product details
            product_name = item.find("div", class_="product__name hidden visible-sm")  # Updated class for name
            product_price = item.find("div", class_="product__price-wrap flc")  # Updated class for price
            product_code = item.find("input", {"name": "id"})  # Hidden input field for product code
            product_availability = item.find("div", class_="product__availability")  # Adjust based on actual class

            # Clean and process the price
            price = product_price.text.strip() if product_price else 'N/A'
            price = price.replace(" դր", "").replace(",", "").strip()  # Remove currency and clean format
            price = int(price) if price.isdigit() else price  # Convert to integer if it's numeric

            # Store the data
            product_data = {
                'Ապրանքի անվանում': product_name.text.strip() if product_name else 'N/A',
                'Գին': price,
                'Ապրանքի կոդ': product_code["value"] if product_code else 'N/A',
                'Հասանելիություն': 'Available' if product_price else 'Unavailable',  # Example for availability
            }
            product_list.append(product_data)
    else:
        print("Product grid not found.")
else:
    print(f"Failed to fetch the page. Status code: {response.status_code}")

# Create a DataFrame from the scraped data
df = pd.DataFrame(product_list)

# Display the DataFrame
print("\nScraped Products:")
print(df)

# Optionally, save to a CSV file
df.to_csv("scraped_products.csv", index=False, encoding='utf-8')

import pandas as pd
from bs4 import BeautifulSoup
import requests

product_list = []
# Առանց Խոլեստերին ապրանքներ
# Define the URL of the page to scrape
url = "https://www.sas.am/catalog/produkty_bez_soderzhaniya_kholesterina/"
response = requests.get(url)

if response.status_code == 200:  # Check if request was successful
    soup = BeautifulSoup(response.content, "html.parser")
    print("Page content fetched successfully.")

    # Locate the product grid
    product_grid = soup.find("div", class_="catalog__grid grid")
    if product_grid:
        print("Catalog grid found.")

        # Locate each product within the grid
        each_product = product_grid.find_all("div", class_="catalog__col col-xl-3 col-lg-3 col-md-4 col-sm-6 col-xs-12")
        print(f"Found {len(each_product)} products.")

        for item in each_product:
            # Extract product details
            product_name = item.find("div", class_="product__name hidden visible-sm")  # Updated class for name
            product_price = item.find("div", class_="product__price-wrap flc")  # Updated class for price
            product_code = item.find("input", {"name": "id"})  # Hidden input field for product code
            product_availability = item.find("div", class_="product__availability")  # Adjust based on actual class

            # Clean and process the price
            price = product_price.text.strip() if product_price else 'N/A'
            price = price.replace(" դր", "").replace(",", "").strip()  # Remove currency and clean format
            price = int(price) if price.isdigit() else price  # Convert to integer if it's numeric

            # Store the data
            product_data = {
                'Ապրանքի անվանում': product_name.text.strip() if product_name else 'N/A',
                'Գին': price,
                'Ապրանքի կոդ': product_code["value"] if product_code else 'N/A',
                'Հասանելիություն': 'Available' if product_price else 'Unavailable',  # Example for availability
            }
            product_list.append(product_data)
    else:
        print("Product grid not found.")
else:
    print(f"Failed to fetch the page. Status code: {response.status_code}")

# Create a DataFrame from the scraped data
df = pd.DataFrame(product_list)

# Display the DataFrame
print("\nScraped Products:")
print(df)

# Optionally, save to a CSV file
df.to_csv("scraped_products.csv", index=False, encoding='utf-8')

import pandas as pd
from bs4 import BeautifulSoup
import requests

product_list = []
#խոլեստերին նվազեցնող ապրանքներ
# Define the URL of the page to scrape
url = "https://www.sas.am/catalog/produkty_ponizhayushchie_kholesterin1/"
response = requests.get(url)

if response.status_code == 200:  # Check if request was successful
    soup = BeautifulSoup(response.content, "html.parser")
    print("Page content fetched successfully.")

    # Locate the product grid
    product_grid = soup.find("div", class_="catalog__grid grid")
    if product_grid:
        print("Catalog grid found.")

        # Locate each product within the grid
        each_product = product_grid.find_all("div", class_="catalog__col col-xl-3 col-lg-3 col-md-4 col-sm-6 col-xs-12")
        print(f"Found {len(each_product)} products.")

        for item in each_product:
            # Extract product details
            product_name = item.find("div", class_="product__name hidden visible-sm")  # Updated class for name
            product_price = item.find("div", class_="product__price-wrap flc")  # Updated class for price
            product_code = item.find("input", {"name": "id"})  # Hidden input field for product code
            product_availability = item.find("div", class_="product__availability")  # Adjust based on actual class

            # Clean and process the price
            price = product_price.text.strip() if product_price else 'N/A'
            price = price.replace(" դր", "").replace(",", "").strip()  # Remove currency and clean format
            price = int(price) if price.isdigit() else price  # Convert to integer if it's numeric

            # Store the data
            product_data = {
                'Ապրանքի անվանում': product_name.text.strip() if product_name else 'N/A',
                'Գին': price,
                'Ապրանքի կոդ': product_code["value"] if product_code else 'N/A',
                'Հասանելիություն': 'Available' if product_price else 'Unavailable',  # Example for availability
            }
            product_list.append(product_data)
    else:
        print("Product grid not found.")
else:
    print(f"Failed to fetch the page. Status code: {response.status_code}")

# Create a DataFrame from the scraped data
df = pd.DataFrame(product_list)

# Display the DataFrame
print("\nScraped Products:")
print(df)

# Optionally, save to a CSV file
df.to_csv("scraped_products.csv", index=False, encoding='utf-8')

import pandas as pd
from bs4 import BeautifulSoup
import requests

product_list = []
#օրգանիկ քաղցրավենիք
# Define the URL of the page to scrape
url = "https://www.sas.am/catalog/sladostiorganic/"
response = requests.get(url)

if response.status_code == 200:  # Check if request was successful
    soup = BeautifulSoup(response.content, "html.parser")
    print("Page content fetched successfully.")

    # Locate the product grid
    product_grid = soup.find("div", class_="catalog__grid grid")
    if product_grid:
        print("Catalog grid found.")

        # Locate each product within the grid
        each_product = product_grid.find_all("div", class_="catalog__col col-xl-3 col-lg-3 col-md-4 col-sm-6 col-xs-12")
        print(f"Found {len(each_product)} products.")

        for item in each_product:
            # Extract product details
            product_name = item.find("div", class_="product__name hidden visible-sm")  # Updated class for name
            product_price = item.find("div", class_="product__price-wrap flc")  # Updated class for price
            product_code = item.find("input", {"name": "id"})  # Hidden input field for product code
            product_availability = item.find("div", class_="product__availability")  # Adjust based on actual class

            # Clean and process the price
            price = product_price.text.strip() if product_price else 'N/A'
            price = price.replace(" դր", "").replace(",", "").strip()  # Remove currency and clean format
            price = int(price) if price.isdigit() else price  # Convert to integer if it's numeric

            # Store the data
            product_data = {
                'Ապրանքի անվանում': product_name.text.strip() if product_name else 'N/A',
                'Գին': price,
                'Ապրանքի կոդ': product_code["value"] if product_code else 'N/A',
                'Հասանելիություն': 'Available' if product_price else 'Unavailable',  # Example for availability
            }
            product_list.append(product_data)
    else:
        print("Product grid not found.")
else:
    print(f"Failed to fetch the page. Status code: {response.status_code}")

# Create a DataFrame from the scraped data
df = pd.DataFrame(product_list)

# Display the DataFrame
print("\nScraped Products:")
print(df)

# Optionally, save to a CSV file
df.to_csv("scraped_products.csv", index=False, encoding='utf-8')

import pandas as pd
from bs4 import BeautifulSoup
import requests

product_list = []
#օրգանիկ ըմպելիք
# Define the URL of the page to scrape
url = "https://www.sas.am/catalog/sokinapitki/"
response = requests.get(url)

if response.status_code == 200:  # Check if request was successful
    soup = BeautifulSoup(response.content, "html.parser")
    print("Page content fetched successfully.")

    # Locate the product grid
    product_grid = soup.find("div", class_="catalog__grid grid")
    if product_grid:
        print("Catalog grid found.")

        # Locate each product within the grid
        each_product = product_grid.find_all("div", class_="catalog__col col-xl-3 col-lg-3 col-md-4 col-sm-6 col-xs-12")
        print(f"Found {len(each_product)} products.")

        for item in each_product:
            # Extract product details
            product_name = item.find("div", class_="product__name hidden visible-sm")  # Updated class for name
            product_price = item.find("div", class_="product__price-wrap flc")  # Updated class for price
            product_code = item.find("input", {"name": "id"})  # Hidden input field for product code
            product_availability = item.find("div", class_="product__availability")  # Adjust based on actual class

            # Clean and process the price
            price = product_price.text.strip() if product_price else 'N/A'
            price = price.replace(" դր", "").replace(",", "").strip()  # Remove currency and clean format
            price = int(price) if price.isdigit() else price  # Convert to integer if it's numeric

            # Store the data
            product_data = {
                'Ապրանքի անվանում': product_name.text.strip() if product_name else 'N/A',
                'Գին': price,
                'Ապրանքի կոդ': product_code["value"] if product_code else 'N/A',
                'Հասանելիություն': 'Available' if product_price else 'Unavailable',  # Example for availability
            }
            product_list.append(product_data)
    else:
        print("Product grid not found.")
else:
    print(f"Failed to fetch the page. Status code: {response.status_code}")

# Create a DataFrame from the scraped data
df = pd.DataFrame(product_list)

# Display the DataFrame
print("\nScraped Products:")
print(df)

# Optionally, save to a CSV file
df.to_csv("scraped_products.csv", index=False, encoding='utf-8')

import pandas as pd
from bs4 import BeautifulSoup
import requests

product_list = []
#օրգանիկ նպարեղեն
# Define the URL of the page to scrape
url = "https://www.sas.am/catalog/bakaleyaorganic/"
response = requests.get(url)

if response.status_code == 200:  # Check if request was successful
    soup = BeautifulSoup(response.content, "html.parser")
    print("Page content fetched successfully.")

    # Locate the product grid
    product_grid = soup.find("div", class_="catalog__grid grid")
    if product_grid:
        print("Catalog grid found.")

        # Locate each product within the grid
        each_product = product_grid.find_all("div", class_="catalog__col col-xl-3 col-lg-3 col-md-4 col-sm-6 col-xs-12")
        print(f"Found {len(each_product)} products.")

        for item in each_product:
            # Extract product details
            product_name = item.find("div", class_="product__name hidden visible-sm")  # Updated class for name
            product_price = item.find("div", class_="product__price-wrap flc")  # Updated class for price
            product_code = item.find("input", {"name": "id"})  # Hidden input field for product code
            product_availability = item.find("div", class_="product__availability")  # Adjust based on actual class

            # Clean and process the price
            price = product_price.text.strip() if product_price else 'N/A'
            price = price.replace(" դր", "").replace(",", "").strip()  # Remove currency and clean format
            price = int(price) if price.isdigit() else price  # Convert to integer if it's numeric

            # Store the data
            product_data = {
                'Ապրանքի անվանում': product_name.text.strip() if product_name else 'N/A',
                'Գին': price,
                'Ապրանքի կոդ': product_code["value"] if product_code else 'N/A',
                'Հասանելիություն': 'Available' if product_price else 'Unavailable',  # Example for availability
            }
            product_list.append(product_data)
    else:
        print("Product grid not found.")
else:
    print(f"Failed to fetch the page. Status code: {response.status_code}")

# Create a DataFrame from the scraped data
df = pd.DataFrame(product_list)

# Display the DataFrame
print("\nScraped Products:")
print(df)

# Optionally, save to a CSV file
df.to_csv("scraped_products.csv", index=False, encoding='utf-8')

import pandas as pd
from bs4 import BeautifulSoup
import requests

product_list = []
#առանց գլյուտեն
# Define the URL of the page to scrape
url = "https://www.sas.am/catalog/bez_glyutena/?LIMIT=60"
response = requests.get(url)

if response.status_code == 200:  # Check if request was successful
    soup = BeautifulSoup(response.content, "html.parser")
    print("Page content fetched successfully.")

    # Locate the product grid
    product_grid = soup.find("div", class_="catalog__grid grid")
    if product_grid:
        print("Catalog grid found.")

        # Locate each product within the grid
        each_product = product_grid.find_all("div", class_="catalog__col col-xl-3 col-lg-3 col-md-4 col-sm-6 col-xs-12")
        print(f"Found {len(each_product)} products.")

        for item in each_product:
            # Extract product details
            product_name = item.find("div", class_="product__name hidden visible-sm")  # Updated class for name
            product_price = item.find("div", class_="product__price-wrap flc")  # Updated class for price
            product_code = item.find("input", {"name": "id"})  # Hidden input field for product code
            product_availability = item.find("div", class_="product__availability")  # Adjust based on actual class

            # Clean and process the price
            price = product_price.text.strip() if product_price else 'N/A'
            price = price.replace(" դր", "").replace(",", "").strip()  # Remove currency and clean format
            price = int(price) if price.isdigit() else price  # Convert to integer if it's numeric

            # Store the data
            product_data = {
                'Ապրանքի անվանում': product_name.text.strip() if product_name else 'N/A',
                'Գին': price,
                'Ապրանքի կոդ': product_code["value"] if product_code else 'N/A',
                'Հասանելիություն': 'Available' if product_price else 'Unavailable',  # Example for availability
            }
            product_list.append(product_data)
    else:
        print("Product grid not found.")
else:
    print(f"Failed to fetch the page. Status code: {response.status_code}")

# Create a DataFrame from the scraped data
df = pd.DataFrame(product_list)

# Display the DataFrame
print("\nScraped Products:")
print(df)

# Optionally, save to a CSV file
df.to_csv("scraped_products.csv", index=False, encoding='utf-8')

import pandas as pd
from bs4 import BeautifulSoup
import requests

product_list = []

# Loop through the 3 pages
for page_number in range(1, 4):  # Adjust range to match the number of pages
    url = f"https://www.sas.am/catalog/bez_glyutena/?page={page_number}&LIMIT=60"
    response = requests.get(url)

    if response.status_code == 200:  # Check if request was successful
        soup = BeautifulSoup(response.content, "html.parser")
        print(f"Page {page_number} content fetched successfully.")

        # Locate the product grid
        product_grid = soup.find("div", class_="catalog__grid grid")
        if product_grid:
            print(f"Catalog grid found on page {page_number}.")

            # Locate each product within the grid
            each_product = product_grid.find_all(
                "div", class_="catalog__col col-xl-3 col-lg-3 col-md-4 col-sm-6 col-xs-12"
            )
            print(f"Found {len(each_product)} products on page {page_number}.")

            for item in each_product:
                # Extract product details
                product_name = item.find("div", class_="product__name hidden visible-sm")
                product_price = item.find("div", class_="product__price-wrap flc")
                product_code = item.find("input", {"name": "id"})
                product_availability = item.find("div", class_="product__availability")

                # Clean and process the price
                price = product_price.text.strip() if product_price else "N/A"
                price = price.replace(" դր", "").replace(",", "").strip()  # Remove currency and clean format
                price = int(price) if price.isdigit() else price  # Convert to integer if it's numeric

                # Store the data
                product_data = {
                    "Ապրանքի անվանում": product_name.text.strip() if product_name else "N/A",
                    "Գին": price,
                    "Ապրանքի կոդ": product_code["value"] if product_code else "N/A",
                    "Հասանելիություն": "Available" if product_price else "Unavailable",  # Example for availability
                }
                product_list.append(product_data)
        else:
            print(f"Product grid not found on page {page_number}.")
    else:
        print(f"Failed to fetch page {page_number}. Status code: {response.status_code}")

# Create a DataFrame from the scraped data
df = pd.DataFrame(product_list)

# Display the DataFrame
print("\nScraped Products:")
print(df)

# Optionally, save to a CSV file
df.to_csv("scraped_products.csv", index=False, encoding="utf-8")

import pandas as pd
from bs4 import BeautifulSoup
import requests

product_list = []

# Define the URL of the page to scrape
url = "https://www.sas.am/catalog/bez_glyutena/?LIMIT=60"
response = requests.get(url)

if response.status_code == 200:  # Check if the request was successful
    soup = BeautifulSoup(response.content, "html.parser")
    print("Page content fetched successfully.")

    # Locate the product grid
    product_grid = soup.find("div", class_="catalog__grid grid")
    if product_grid:
        print("Catalog grid found.")

        # Locate each product within the grid
        each_product = product_grid.find_all("div", class_="catalog__col col-xl-3 col-lg-3 col-md-4 col-sm-6 col-xs-12")
        print(f"Found {len(each_product)} products.")

        for item in each_product:
            # Extract product details
            product_name = item.find("div", class_="product__name")
            product_price = item.find("div", class_="product__price-wrap")
            product_code = item.find("input", {"name": "id"})  # Hidden input field for product code
            product_availability = item.find("div", class_="product__availability")
            product_image = item.find("img")  # Locate the image tag

            # Clean and process the price
            price = product_price.text.strip() if product_price else 'N/A'
            price = price.replace(" դր", "").replace(",", "").strip()  # Remove currency and clean format
            price = int(price) if price.isdigit() else price  # Convert to integer if numeric

            # Extract image URL
            image_url = f"https://www.sas.am{image_url}" if image_url.startswith("/") else image_url

            # Store the data
            product_data = {
                'Ապրանքի անվանում': product_name.text.strip() if product_name else 'N/A',
                'Գին': price,
                'Ապրանքի կոդ': product_code["value"] if product_code else 'N/A',
                'Հասանելիություն': 'Available' if product_price else 'Unavailable',  # Example for availability
                'Նկարի հղում': image_url,
            }
            product_list.append(product_data)
    else:
        print("Product grid not found.")
else:
    print(f"Failed to fetch the page. Status code: {response.status_code}")

# Create a DataFrame from the scraped data
df = pd.DataFrame(product_list)

# Display the DataFrame
print("\nScraped Products:")
print(df)

# Optionally, save to a CSV file
df.to_csv("scraped_products.csv", index=False, encoding='utf-8')

from datetime import datetime

# Extended product data
products = [
    {"name": "Product A", "production_date": "2024-01-01", "expiration_date": "2024-12-31", "price": 100},
    {"name": "Product B", "production_date": "2024-06-01", "expiration_date": "2024-12-01", "price": 200},
    {"name": "Product C", "production_date": "2024-10-01", "expiration_date": "2024-12-31", "price": 150},
    {"name": "Product D", "production_date": "2023-12-01", "expiration_date": "2024-05-01", "price": 80},
    {"name": "Product E", "production_date": "2024-05-01", "expiration_date": "2025-05-01", "price": 250},
    {"name": "Product F", "production_date": "2024-07-01", "expiration_date": "2024-10-15", "price": 120},
    {"name": "Product G", "production_date": "2024-08-15", "expiration_date": "2024-12-15", "price": 300},
    {"name": "Product H", "production_date": "2024-02-01", "expiration_date": "2024-11-01", "price": 180},
]

def calculate_discount(products):
    today = datetime.now()
    discounted_products = []

    for product in products:
        # Parse dates
        production_date = datetime.strptime(product["production_date"], "%Y-%m-%d")
        expiration_date = datetime.strptime(product["expiration_date"], "%Y-%m-%d")

        # Calculate the total shelf life and remaining shelf life in days
        total_shelf_life = (expiration_date - production_date).days
        remaining_shelf_life = (expiration_date - today).days

        # Calculate the remaining percentage
        remaining_percentage = (remaining_shelf_life / total_shelf_life) * 100 if total_shelf_life > 0 else 0

        # Determine if a discount is applied
        discount = 0
        if remaining_percentage < 20:
            discount = product["price"] * 0.3

        # Add discount and remaining percentage to the product info
        discounted_products.append({
            "name": product["name"],
            "production_date": product["production_date"],
            "expiration_date": product["expiration_date"],
            "price": product["price"],
            "remaining_percentage": remaining_percentage,
            "discounted_price": product["price"] - discount
        })

    return discounted_products

# Apply the discount calculation
result = calculate_discount(products)

# Display the results in a tabular format
print(f"{'Name':<15}{'Production Date':<15}{'Expiration Date':<15}{'Price':<10}{'Remaining %':<12}{'Discounted Price':<15}")
for product in result:
    print(f"{product['name']:<15}{product['production_date']:<15}{product['expiration_date']:<15}{product['price']:<10}{product['remaining_percentage']:<12.2f}{product['discounted_price']:<15.2f}")

import pandas as pd

# Data for snacks, candies, cookies, and other eating products
data = [
    {"Product Name": "Օրեո (Oreo) 150գ", "Packaging Info": "Plastic Wrapper", "Reusability Score": 0.3, "Health Labels": "Non-biodegradable", "Allergens": "Gluten, Dairy"},
    {"Product Name": "ԿիտԿատ (KitKat) 40գ", "Packaging Info": "Plastic Wrapper", "Reusability Score": 0.2, "Health Labels": "Non-biodegradable", "Allergens": "Dairy, Soy"},
    {"Product Name": "Սնիքերս (Snickers) 50գ", "Packaging Info": "Plastic Wrapper", "Reusability Score": 0.2, "Health Labels": "Non-biodegradable", "Allergens": "Peanuts, Dairy"},
    {"Product Name": "Միլկա Շոկոլադ (Milka Chocolate) 100գ", "Packaging Info": "Plastic Wrapper", "Reusability Score": 0.3, "Health Labels": "Non-biodegradable", "Allergens": "Dairy"},
    {"Product Name": "Թաֆի (Taffy Candy) 100գ", "Packaging Info": "Plastic Wrapper", "Reusability Score": 0.2, "Health Labels": "Non-biodegradable", "Allergens": "None"},
    {"Product Name": "Թթվասեր Սմարթիս (Sour Smarties) 50գ", "Packaging Info": "Plastic Tube", "Reusability Score": 0.4, "Health Labels": "Non-biodegradable", "Allergens": "None"},
    {"Product Name": "ՄՄԴ (M&M's) 100գ", "Packaging Info": "Plastic Bag", "Reusability Score": 0.3, "Health Labels": "Non-biodegradable", "Allergens": "Dairy, Peanuts"},
    {"Product Name": "Մարշմալո (Marshmallow) 100գ", "Packaging Info": "Plastic Wrapper", "Reusability Score": 0.2, "Health Labels": "Non-biodegradable", "Allergens": "None"},
    {"Product Name": "Չիպսեր (Potato Chips) 200գ", "Packaging Info": "Plastic Bag", "Reusability Score": 0.2, "Health Labels": "Non-biodegradable", "Allergens": "None"},
    {"Product Name": "Դորիտոս (Doritos) 150գ", "Packaging Info": "Plastic Bag", "Reusability Score": 0.2, "Health Labels": "Non-biodegradable", "Allergens": "None"},
    {"Product Name": "Պոպկորն (Popcorn) 100գ", "Packaging Info": "Plastic Bag", "Reusability Score": 0.2, "Health Labels": "Non-biodegradable", "Allergens": "None"},
    {"Product Name": "Սուպեր Քուկի (Super Cookie) 150գ", "Packaging Info": "Plastic Wrapper", "Reusability Score": 0.3, "Health Labels": "Non-biodegradable", "Allergens": "Gluten, Dairy"},
    {"Product Name": "Պրետցելներ (Pretzels) 200գ", "Packaging Info": "Plastic Bag", "Reusability Score": 0.2, "Health Labels": "Non-biodegradable", "Allergens": "Gluten"},
    {"Product Name": "Ֆրունչ Սթիքս (Crunch Sticks) 100գ", "Packaging Info": "Plastic Wrapper", "Reusability Score": 0.2, "Health Labels": "Non-biodegradable", "Allergens": "None"},
    {"Product Name": "Բաունթի (Bounty) 50գ", "Packaging Info": "Plastic Wrapper", "Reusability Score": 0.2, "Health Labels": "Non-biodegradable", "Allergens": "Coconut, Dairy"},
    {"Product Name": "Տոբլերոնե (Toblerone) 100գ", "Packaging Info": "Cardboard Box", "Reusability Score": 0.8, "Health Labels": "Eco-friendly, Recyclable", "Allergens": "Dairy, Nuts"},
    {"Product Name": "Սփրիտ Քենդի (Sprite Candy) 50գ", "Packaging Info": "Plastic Wrapper", "Reusability Score": 0.2, "Health Labels": "Non-biodegradable", "Allergens": "None"},
    {"Product Name": "Հրուշակ (Nougat Candy) 100գ", "Packaging Info": "Plastic Wrapper", "Reusability Score": 0.2, "Health Labels": "Non-biodegradable", "Allergens": "Nuts, Dairy"},
    {"Product Name": "Միկադո Սթիքս (Mikado Sticks) 75գ", "Packaging Info": "Plastic Wrapper", "Reusability Score": 0.3, "Health Labels": "Non-biodegradable", "Allergens": "Gluten"},
    {"Product Name": "Նուտելլա Բիսքվիթ (Nutella Biscuit) 150գ", "Packaging Info": "Plastic Wrapper", "Reusability Score": 0.2, "Health Labels": "Non-biodegradable", "Allergens": "Gluten, Dairy, Hazelnut"},
    {"Product Name": "Մաքսի Կոուքի (Maxi Cookie) 200գ", "Packaging Info": "Plastic Wrapper", "Reusability Score": 0.3, "Health Labels": "Non-biodegradable", "Allergens": "Gluten, Dairy"},
    {"Product Name": "Չիթոս (Cheetos) 150գ", "Packaging Info": "Plastic Bag", "Reusability Score": 0.2, "Health Labels": "Non-biodegradable", "Allergens": "None"},
    {"Product Name": "Կրեկեր (Crackers) 200գ", "Packaging Info": "Plastic Bag", "Reusability Score": 0.2, "Health Labels": "Non-biodegradable", "Allergens": "Gluten"},
    {"Product Name": "Բրիկետներ (Granola Bars) 100գ", "Packaging Info": "Plastic Wrapper", "Reusability Score": 0.2, "Health Labels": "Non-biodegradable", "Allergens": "Nuts"},
    {"Product Name": "Լեվե Ֆրեշ (Leve Fresh Gum) 50գ", "Packaging Info": "Plastic Wrapper", "Reusability Score": 0.2, "Health Labels": "Non-biodegradable", "Allergens": "None"},
    {"Product Name": "Խնձոր (Apple) 1կգ", "Packaging Info": "Paper Bag", "Reusability Score": 0.7, "Health Labels": "Organic, Biodegradable", "Allergens": "None"},
    {"Product Name": "Բանան (Banana) 1կգ", "Packaging Info": "Plastic Wrapper", "Reusability Score": 0.3, "Health Labels": "Non-biodegradable", "Allergens": "None"},
    {"Product Name": "Տանձ (Pear) 1կգ", "Packaging Info": "Cardboard Box", "Reusability Score": 0.8, "Health Labels": "Eco-friendly, Recyclable", "Allergens": "None"},
    {"Product Name": "Խաղող (Grapes) 1կգ", "Packaging Info": "Biodegradable Plastic", "Reusability Score": 0.6, "Health Labels": "Eco-friendly, Biodegradable", "Allergens": "None"},
    {"Product Name": "Նարինջ (Orange) 1կգ", "Packaging Info": "Plastic Wrapper", "Reusability Score": 0.3, "Health Labels": "Non-biodegradable", "Allergens": "None"},
    {"Product Name": "Կիվի (Kiwi) 1կգ", "Packaging Info": "Cardboard Box", "Reusability Score": 0.8, "Health Labels": "Eco-friendly, Recyclable", "Allergens": "None"},
    {"Product Name": "Սեխ (Melon) 1կգ", "Packaging Info": "Paper Bag", "Reusability Score": 0.7, "Health Labels": "Organic, Biodegradable", "Allergens": "None"},
    {"Product Name": "Սերկեւիլ (Quince) 1կգ", "Packaging Info": "Plastic Wrapper", "Reusability Score": 0.3, "Health Labels": "Non-biodegradable", "Allergens": "None"},
    {"Product Name": "Բալի (Cherry) 1կգ", "Packaging Info": "Biodegradable Plastic", "Reusability Score": 0.6, "Health Labels": "Eco-friendly, Biodegradable", "Allergens": "None"},
    {"Product Name": "Մանդարին (Mandarin) 1կգ", "Packaging Info": "Paper Bag", "Reusability Score": 0.7, "Health Labels": "Organic, Biodegradable", "Allergens": "None"},
    {"Product Name": "Կարտոֆիլ (Potato) 1կգ", "Packaging Info": "Mesh Bag", "Reusability Score": 0.5, "Health Labels": "Eco-friendly, Recyclable", "Allergens": "None"},
    {"Product Name": "Սոխ (Onion) 1կգ", "Packaging Info": "Mesh Bag", "Reusability Score": 0.5, "Health Labels": "Eco-friendly, Recyclable", "Allergens": "None"},
    {"Product Name": "Սմբուկ (Eggplant) 1կգ", "Packaging Info": "Plastic Wrapper", "Reusability Score": 0.3, "Health Labels": "Non-biodegradable", "Allergens": "None"},
    {"Product Name": "Լոլիկ (Tomato) 1կգ", "Packaging Info": "Paper Bag", "Reusability Score": 0.7, "Health Labels": "Organic, Biodegradable", "Allergens": "None"},
    {"Product Name": "Վարունգ (Cucumber) 1կգ", "Packaging Info": "Plastic Wrapper", "Reusability Score": 0.3, "Health Labels": "Non-biodegradable", "Allergens": "None"},
    {"Product Name": "Գազար (Carrot) 1կգ", "Packaging Info": "Mesh Bag", "Reusability Score": 0.5, "Health Labels": "Eco-friendly, Recyclable", "Allergens": "None"},
    {"Product Name": "Բազուկ (Beetroot) 1կգ", "Packaging Info": "Paper Bag", "Reusability Score": 0.7, "Health Labels": "Organic, Biodegradable", "Allergens": "None"},
    {"Product Name": "Բուլղարական պղպեղ (Bell Pepper) 1կգ", "Packaging Info": "Plastic Wrapper", "Reusability Score": 0.3, "Health Labels": "Non-biodegradable", "Allergens": "None"},
    {"Product Name": "Սպանախ (Spinach) 1կգ", "Packaging Info": "Paper Bag", "Reusability Score": 0.7, "Health Labels": "Organic, Biodegradable", "Allergens": "None"},
    {"Product Name": "Ծաղկակաղամբ (Cauliflower) 1կգ", "Packaging Info": "Biodegradable Plastic", "Reusability Score": 0.6, "Health Labels": "Eco-friendly, Biodegradable", "Allergens": "None"},
    {"Product Name": "Ծիրանաչիր (Dried Apricot) 1կգ", "Packaging Info": "Plastic Wrapper", "Reusability Score": 0.3, "Health Labels": "Non-biodegradable", "Allergens": "None"},
    {"Product Name": "Սալորաչիր (Dried Plum) 1կգ", "Packaging Info": "Plastic Wrapper", "Reusability Score": 0.3, "Health Labels": "Non-biodegradable", "Allergens": "None"},
    {"Product Name": "Ընկույզ (Walnut) 1կգ", "Packaging Info": "Paper Bag", "Reusability Score": 0.7, "Health Labels": "Organic, Biodegradable", "Allergens": "Tree Nuts"},
    {"Product Name": "Նուշ (Almond) 1կգ", "Packaging Info": "Plastic Wrapper", "Reusability Score": 0.3, "Health Labels": "Non-biodegradable", "Allergens": "Tree Nuts"},
    {"Product Name": "Սունկ (Mushroom) 1կգ", "Packaging Info": "Plastic Wrapper", "Reusability Score": 0.3, "Health Labels": "Non-biodegradable", "Allergens": "None"},
    {"Product Name": "Հաց (Bread) 500գ", "Packaging Info": "Paper Bag", "Reusability Score": 0.7, "Health Labels": "Biodegradable, Organic", "Allergens": "Gluten"},
    {"Product Name": "Պանիր (Cheese) 1կգ", "Packaging Info": "Plastic Wrapper", "Reusability Score": 0.3, "Health Labels": "Non-biodegradable", "Allergens": "Dairy"},
    {"Product Name": "Կաթնաշոռ (Cottage Cheese) 500գ", "Packaging Info": "Plastic Wrapper", "Reusability Score": 0.3, "Health Labels": "Non-biodegradable", "Allergens": "Dairy"},
    {"Product Name": "Կաթ (Milk) 1լ", "Packaging Info": "Glass Bottle", "Reusability Score": 0.9, "Health Labels": "Reusable, Recyclable", "Allergens": "Dairy"},
    {"Product Name": "Յոգուրտ (Yogurt) 400գ", "Packaging Info": "Plastic Container", "Reusability Score": 0.4, "Health Labels": "Non-biodegradable", "Allergens": "Dairy"},

]

# Create DataFrame
df = pd.DataFrame(data)

# Display the updated table
print(df)